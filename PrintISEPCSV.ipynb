{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dash\n",
    "import dash_table\n",
    "import time\n",
    "from fake_useragent import UserAgent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#constants\n",
    "#headers = {'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.142 Safari/537.36'}\n",
    "#headers = {'User-Agent': 'Mozilla/5.0 (Linux; Android 10; ONEPLUS A5010) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.159 Mobile Safari/537.36'}\n",
    "#headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:50.0) Gecko/20100101 Firefox/50.0'}\n",
    "#headers = {'User-Agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.164 Safari/537.36 OPR/77.0.4054.277'}\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.14; rv:66.0) Gecko/20100101 Firefox/66.0\", \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\", \"Accept-Language\": \"en-US,en;q=0.5\", \"Accept-Encoding\": \"gzip, deflate\", \"DNT\": \"1\", \"Connection\": \"close\", \"Upgrade-Insecure-Requests\": \"1\"}\n",
    "base_url = \"https://www.niche.com/colleges/\"\n",
    "#filename = \"./Grad\"      #without .csv!\n",
    "filename = \"./Grad\"\n",
    "ua = UserAgent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------Load and translate ISEP CSV table------------------\n",
    "def loadNameList(filename):\n",
    "    df = pd.read_csv(filename + \".csv\")\n",
    "    return list(df[\"University Name\"]), list(df[\" Chance of Placement\"])\n",
    "    \n",
    "def namelistToURL(namelist):\n",
    "    url_list = []\n",
    "    for uni_name in namelist:\n",
    "        element = uni_name.replace(\" \", \"-\")\n",
    "        element = element.replace(\"&\", \"-and-\")\n",
    "        element = element.replace(\"â€™\", \"\")\n",
    "        url_list.append(element)\n",
    "        \n",
    "    return url_list\n",
    "\n",
    "#-------------------------\n",
    "def getSoup(uni_url):\n",
    "    url = base_url + uni_url + \"/\"\n",
    "\n",
    "    # Make a GET request to fetch the raw HTML content\n",
    "    #user_agent = ua.random\n",
    "    #headers = {'User-Agent': user_agent}\n",
    "    html_content = requests.get(url, headers=headers).text\n",
    "\n",
    "\n",
    "    # Parse the html content\n",
    "    soup = BeautifulSoup(html_content, \"lxml\")\n",
    "    \n",
    "    return soup\n",
    "\n",
    "#---------Get Table Content---------------  \n",
    "def getOverallGrade(soup):\n",
    "    try:\n",
    "        mydivs = soup.find_all(\"div\", {\"class\": \"overall-grade__niche-grade\"})\n",
    "        grade = mydivs[0].contents[0].contents[1]\n",
    "        grade = grade.replace(\" minus\", \"-\")\n",
    "    except:\n",
    "        grade = \"Error\"\n",
    "    return grade\n",
    "\n",
    "def getNameList(soup):\n",
    "    labels = mydivs[0].contents[0].find_all(\"div\", {\"class\": \"profile-grade__label\"})\n",
    "    label_list = []\n",
    "\n",
    "    for label in labels:\n",
    "        label_list.append(label.contents[0])\n",
    "        \n",
    "    return label_list\n",
    "    \n",
    "\n",
    "def getValueList(soup):\n",
    "    mydivs = soup.find_all(\"div\", {\"class\": \"profile__bucket--2\"})\n",
    "    #print(soup.prettify())\n",
    "    values = mydivs[0].contents[0].find_all(\"div\", {\"class\": \"profile-grade--two\"})\n",
    "    value_list = []\n",
    "\n",
    "    for value in values:\n",
    "        element = value.contents[1].contents[1]\n",
    "        element = element.replace(\" minus\", \"-\")\n",
    "        value_list.append(element)\n",
    "        \n",
    "    return value_list\n",
    "\n",
    "def foundSite(soup):\n",
    "    if bool(soup.findAll(text=\"Access to this page has been denied.\")):\n",
    "        print(soup.prettify())\n",
    "        #print(\"Access denied\")\n",
    "        return False\n",
    "            \n",
    "    if bool(soup.findAll(text=\"Page Not Found\")):\n",
    "        return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "def getStudentCount(soup):\n",
    "    try:\n",
    "        mydivs = soup.find_all(\"section\", {\"aria-label\": \"Students\"})\n",
    "        res = mydivs[0].contents[1].contents[0].contents[0].contents[0].contents[1].contents[0].contents[0]\n",
    "        res = res.replace(\",\",\"\")\n",
    "        res = int(res)\n",
    "    except:\n",
    "        res = \"Error\"\n",
    "        \n",
    "    return res\n",
    "\n",
    "def displayInteractiveTable(df):\n",
    "    app = dash.Dash(__name__)\n",
    "\n",
    "    app.layout = dash_table.DataTable(\n",
    "        id='table',\n",
    "        columns=[{\"name\": i, \"id\": i} for i in df.columns],\n",
    "        data=df.to_dict('records'),\n",
    "        filter_action=\"native\",\n",
    "        sort_action=\"native\",\n",
    "        sort_mode=\"multi\",\n",
    "        row_deletable=True,\n",
    "        editable=True\n",
    "    )\n",
    "\n",
    "    app.run_server( \"127.0.0.1\", 8000,debug=True, use_reloader=False)  # Turn off reloader if inside Jupyter\n",
    "    #app.run_server(debug=True, use_reloader=False)  # Turn off reloader if inside Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "' Chance of Placement'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\python39\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3079\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3080\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: ' Chance of Placement'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-14912d52f210>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mname_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplacement_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloadNameList\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0murl_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnamelistToURL\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#setup data lists\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mniche_score_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-6a9921b4d441>\u001b[0m in \u001b[0;36mloadNameList\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mloadNameList\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\".csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"University Name\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\" Chance of Placement\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mnamelistToURL\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnamelist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python39\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3022\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3023\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3024\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3025\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python39\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3080\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3082\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3084\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: ' Chance of Placement'"
     ]
    }
   ],
   "source": [
    "\n",
    "name_list, placement_list = loadNameList(filename)\n",
    "url_list = namelistToURL(name_list)\n",
    "\n",
    "#setup data lists\n",
    "niche_score_list = []\n",
    "report_scores = []\n",
    "student_count = []\n",
    "\n",
    "for i, uni_url in enumerate(url_list):\n",
    "    print(str(i) + \"/\" + str(len(name_list)) + \": \"+uni_url)\n",
    "    soup = getSoup(uni_url)\n",
    "    \n",
    "    #if not(foundSite(soup)):\n",
    "    #    new_uni_url = uni_url.replace(\"-at\", \"\")\n",
    "    #    soup = getSoup(new_uni_url)\n",
    "    #    time.sleep(5)\n",
    "    #if not(foundSite(soup)):\n",
    "    #    new_uni_url = uni_url.replace(\",\", \"-\")\n",
    "    #    soup = getSoup(new_uni_url)\n",
    "    #    time.sleep(5)\n",
    "    #if not(foundSite(soup)):\n",
    "    #    new_uni_url = uni_url.replace(\"&\", \"-and-\")\n",
    "    #    soup = getSoup(new_uni_url)\n",
    "    #    time.sleep(5)\n",
    "    if not(foundSite(soup)):\n",
    "        print(\"Page not found, invalid URL: \" + uni_url)\n",
    "        niche_score_list.append(None)\n",
    "        report_scores.append([None, None, None, None, None, None,None, None, None, None, None, None])\n",
    "        student_count.append(None)\n",
    "    else:\n",
    "        niche_score_list.append(getOverallGrade(soup))\n",
    "        report_scores.append(getValueList(soup))\n",
    "        student_count.append(getStudentCount(soup))\n",
    "    \n",
    "    time.sleep(5)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "row_list = []\n",
    "for i, name in enumerate(name_list):\n",
    "    row = []\n",
    "    row.append(name)\n",
    "    row.append(student_count[i])\n",
    "    row.append(placement_list[i])\n",
    "    row.append(niche_score_list[i])\n",
    "    [row.append(item) for item in report_scores[i]]\n",
    "    row_list.append(row)   \n",
    "    \n",
    "\n",
    "    \n",
    "names = [\"University Name\", \"Student Count\", \"Chances of Placement\",\"Overall Niche Grade\",\n",
    "        \"Academics\",\"Value\", \"Diversity\", \"Campus\", \"Athletics\", \"Party Scene\", \"Professors\", \"Location\", \"Dorms\", \"Campus Food\", \"Student Life\", \"Safety\"]\n",
    "df = pd.DataFrame(row_list, columns = names)\n",
    "\n",
    "df.to_csv(filename + \"_result\" + \".csv\")  # where to save it, usually as a .pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash is running on http://127.0.0.1:8000/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8000/\n",
      "\n",
      " * Serving Flask app '__main__' (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: on\n"
     ]
    }
   ],
   "source": [
    "#undergrad_1 = pd.read_csv(\"./Undergrad_1_result.csv\")\n",
    "grad = pd.read_csv(\"./Grad.csv\")\n",
    "grad[\"Ranking\"] = None\n",
    "displayInteractiveTable(grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
